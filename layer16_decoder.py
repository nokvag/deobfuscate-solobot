#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
layer16_decoder.py
  ‚Ä¢ —Å—Ç—Ä–æ–∏—Ç –∫–∞—Ä—Ç—É ¬´–æ–±—Ñ—É—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ_–∏–º—è ‚Üí –Ω–∞—Å—Ç–æ—è—â–µ–µ¬ª
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ç–µ–∂–Ω—ã—Ö –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–π
  ‚Ä¢ –º–∞—Å—Å–æ–≤–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º
  ‚Ä¢ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ layer16.py
"""
from __future__ import annotations
import ast, io, keyword, pathlib, tokenize, builtins

SRC = pathlib.Path("layer15.py")
DST = pathlib.Path("layer16.py")

code = SRC.read_text("utf-8")
module = ast.parse(code, SRC.name)

def resolve_name(node: ast.AST) -> str | None:
    """–ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤—ã—Ç–∞—â–∏—Ç—å ¬´—á–µ—Å—Ç–Ω–æ–µ¬ª –∏–º—è –∏–∑ –≤—ã—Ä–∞–∂–µ–Ω–∏—è."""
    # __import__('pkg.sub')
    if (isinstance(node, ast.Call) and isinstance(node.func, ast.Name)
            and node.func.id == "__import__"
            and node.args and isinstance(node.args[0], ast.Constant)
            and isinstance(node.args[0].value, str)):
        return node.args[0].value.split(".")[-1]

    # getattr(obj, 'Attr')  (–±–µ—Ä—ë–º —Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç)
    if (isinstance(node, ast.Call) and isinstance(node.func, ast.Name)
            and node.func.id == "getattr" and len(node.args) >= 2
            and isinstance(node.args[1], ast.Constant)
            and isinstance(node.args[1].value, str)):
        return node.args[1].value

    # –≤–ª–æ–∂–µ–Ω–Ω—ã–µ getattr(...getattr(...'Attr'))
    if (isinstance(node, ast.Call)
            and isinstance(node.func, ast.Name)
            and node.func.id == "getattr"):
        return resolve_name(node.args[0]) or resolve_name(node.func)

    return None


alias_map: dict[str, str] = {}

for n in module.body:
    if isinstance(n, ast.Assign) and len(n.targets) == 1:
        tgt = n.targets[0]
        if isinstance(tgt, ast.Tuple) and isinstance(n.value, ast.Tuple):
            for left_el, right_el in zip(tgt.elts, n.value.elts):
                if isinstance(left_el, ast.Name):
                    real = resolve_name(right_el)
                    if real and real.isidentifier():
                        alias_map[left_el.id] = real

# —É–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
reserved = set(keyword.kwlist) | set(dir(builtins))
final_map: dict[str, str] = {}
counter: dict[str, int] = {}
for obf, real in alias_map.items():
    if real in reserved:
        continue
    base = real
    if real in final_map.values():
        counter[base] = counter.get(base, 0) + 1
        real = f"{base}_{counter[base]}"
    final_map[obf] = real

print(f"üîç —Å–æ–±—Ä–∞–ª–∏ {len(final_map)} –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π")

# ---------- —Ç–æ–∫–µ–Ω-–∑–∞–º–µ–Ω–∞ ----------
out_tokens = []
stream = io.StringIO(code)
for tok in tokenize.generate_tokens(stream.readline):
    ttype, tstr, *rest = tok
    if ttype == tokenize.NAME and tstr in final_map:
        tstr = final_map[tstr]
    out_tokens.append((ttype, tstr, *rest))

DST.write_text(tokenize.untokenize(out_tokens), "utf-8")
print(f"‚úÖ layer16.py —Å–æ—Ö—Ä–∞–Ω—ë–Ω –ø–æ –ø—É—Ç–∏: {DST}")